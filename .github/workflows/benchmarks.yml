name: benchmarks

on:
  pull_request:
    branches: [master]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        uses: astral-sh/setup-uv@v5

      - name: Set up project
        run: uv sync --dev

      - name: Run benchmarks
        run: |
          uv run pytest -m benchmark --benchmark-enable \
            --benchmark-json=benchmark-results.json \
            --benchmark-columns=mean,stddev,rounds

      - name: Upload benchmark results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: benchmark-results
          path: benchmark-results.json

      - name: Check for regressions
        run: |
          if [ -f .benchmarks/baseline.json ]; then
            uv run pytest-benchmark compare \
              .benchmarks/baseline.json benchmark-results.json \
              --csv=comparison.csv
          else
            echo "No baseline found â€” skipping regression check"
          fi
